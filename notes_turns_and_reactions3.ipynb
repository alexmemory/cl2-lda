{
 "metadata": {
  "name": "notes_turns_and_reactions3"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown", 
     "source": [
      "# Reactions per turn"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Focusing on generating evaluation results for our specific tasks."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "import pandas as pd", 
      "import reactions", 
      "import nltk", 
      "import random", 
      "import matplotlib.pyplot as plt", 
      "from pandas.tools.plotting import scatter_matrix", 
      "from nltk.corpus import stopwords"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "%time r = reactions.link_reactions_to_transcript('data/reactions_oct3_4project.csv','corpora/oct3_coded_transcript_sync.csv')"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "CPU times: user 8.41 s, sys: 0.52 s, total: 8.93 s", 
        "Wall time: 8.93 s"
       ]
      }
     ], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "r2 = r.copy()", 
      "#del r2[\"Sync'd start\"]", 
      "#del r2[\"Sync'd end\"]", 
      "del r2[\"Time\"]", 
      "del r2[\"Speaker\"]", 
      "#r2.head(2)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 3
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Political questionnaire data"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "%time p = reactions.split_reactions_file('data/reactions_oct3_4project.csv')['quest_political']"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "CPU times: user 5.09 s, sys: 0.36 s, total: 5.46 s", 
        "Wall time: 5.46 s"
       ]
      }
     ], 
     "prompt_number": 5
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "p2 = p[['UserID','party_1','political_views_2','candidate_choice_3','confidence_in_choice_4','likely_to_vote_5','candidate_preferred_29']]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 11
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Simplify party membership into R/D/oth"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "p2['party'] = p2.party_1.apply(lambda a: {'closest to democratic party':'democrat', ", 
      "                                          'lean democrat':'democrat',", 
      "                                          'lean republican':'republican',", 
      "                                          'closest to republican party':'republican'}.get(a,'other'))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 13
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "### Merge political questionnaire with reactions"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "%time r3 = r2.merge(p2[['UserID','party']])", 
      "print 'pre-merge:',len(r2),'post-merge:',len(r3)", 
      "#r3.head(2)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "CPU times: user 0.64 s, sys: 0.04 s, total: 0.68 s", 
        "Wall time: 0.68 s", 
        "pre-merge: 189015 post-merge: 189015"
       ]
      }
     ], 
     "prompt_number": 14
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Limit to reactions to the speaker of the ***current turn***."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "r4 = r3[r3.Reaction_who == r3.Speaker_name]", 
      "print 'before:',len(r3),'current-speaker-only:',len(r4), 'difference:',len(r4)-len(r3), 1.0*(len(r4)-len(r3))/len(r4),'percent'"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "before: 189015 current-speaker-only: 156622 difference: -32393 -0.206822796287 percent"
       ]
      }
     ], 
     "prompt_number": 15
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Group by turn"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Statements"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "st = r4.groupby(['statement']).first()[['Speaker_name','Transcript','turn',\"Sync'd start\",\"Sync'd end\"]]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 17
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Turns"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "t = pd.DataFrame({'speaker':st.groupby('turn').first().Speaker_name, ", 
      "                  'start':st.groupby('turn').first()[\"Sync'd start\"],", 
      "                  'end':st.groupby('turn').last()[\"Sync'd end\"],", 
      "                  'reactions':r4.groupby('turn').count().Speaker_name, ", 
      "                  'statements':st.groupby('turn').count().turn, ", 
      "                  'text':st.groupby('turn').apply(lambda x: ''.join(x.Transcript)),", 
      "                  'agree':r4[r4.Reaction_what=='Agree'].groupby('turn').count().turn,", 
      "                  'agree_dem':r4[(r4.party=='democrat') & (r4.Reaction_what=='Agree')].groupby('turn').count().turn,", 
      "                  'agree_rep':r4[(r4.party=='republican') & (r4.Reaction_what=='Agree')].groupby('turn').count().turn,", 
      "                  'disagree':r4[r4.Reaction_what=='Disagree'].groupby('turn').count().turn,", 
      "                  'disagree_dem':r4[(r4.party=='democrat') & (r4.Reaction_what=='Disagree')].groupby('turn').count().turn,", 
      "                  'disagree_rep':r4[(r4.party=='republican') & (r4.Reaction_what=='Disagree')].groupby('turn').count().turn,", 
      "                  'dodge':r4[r4.Reaction_what=='Dodge'].groupby('turn').count().turn,", 
      "                  'spin':r4[r4.Reaction_what=='Spin'].groupby('turn').count().turn,", 
      "                  })", 
      "tmpstart = pd.to_datetime(t.start)", 
      "tmpend = pd.to_datetime(t.end)", 
      "t['dur'] = (tmpend - tmpstart)", 
      "t.duration = 1.0 * t.dur / 1000000000.0", 
      "t['words'] = t.text.apply(lambda txt: [tok.lower() for tok in nltk.tokenize.word_tokenize(txt) if tok.isalpha()])", 
      "t['word_count'] = t.words.apply(lambda words: len(words))", 
      "t['r_per_st'] = 1.0 * t.reactions / t.statements", 
      "t['r_per_w'] = 1.0 * t.reactions / t.word_count", 
      "t['r_per_sec'] = 1.0 * t.reactions / t.dur", 
      "t['sd_per_sec'] = 1.0 * (t.spin + t.dodge) / t.dur", 
      "t['a_to_d_dems'] = t.agree_dem / t.disagree_dem", 
      "t['a_to_d_reps'] = t.agree_rep / t.disagree_rep", 
      "", 
      "del t['agree']", 
      "#del t['agree_dem']", 
      "#del t['agree_rep']", 
      "del t['disagree']", 
      "#del t['disagree_dem']", 
      "#del t['disagree_rep']", 
      "del t['dodge']", 
      "del t['spin']", 
      "del t['r_per_st']", 
      "del t['r_per_w']", 
      "del t['start']", 
      "del t['end']", 
      "del t['dur']"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 23
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "ranked_unigrams = nltk.FreqDist([w for word_list in t.words for w in word_list]).keys()", 
      "#MAX_FEATURES = 700 # avoid overfitting", 
      "MAX_FEATURES = 200 # avoid overfitting", 
      "t['unigrams'] = t.words.apply(lambda words: {w:True for w in words if w in ranked_unigrams[:MAX_FEATURES] and not w in stopwords.words('english')})", 
      "t['unigram_count'] = t.unigrams.apply(lambda unigrams: len(unigrams))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 166
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "t.head(2)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">", 
        "<table border=\"1\" class=\"dataframe\">", 
        "  <thead>", 
        "    <tr style=\"text-align: right;\">", 
        "      <th></th>", 
        "      <th>agree_dem</th>", 
        "      <th>agree_rep</th>", 
        "      <th>disagree_dem</th>", 
        "      <th>disagree_rep</th>", 
        "      <th>reactions</th>", 
        "      <th>speaker</th>", 
        "      <th>statements</th>", 
        "      <th>text</th>", 
        "      <th>words</th>", 
        "      <th>word_count</th>", 
        "      <th>r_per_sec</th>", 
        "      <th>sd_per_sec</th>", 
        "      <th>a_to_d_dems</th>", 
        "      <th>a_to_d_reps</th>", 
        "      <th>unigrams</th>", 
        "      <th>unigram_count</th>", 
        "    </tr>", 
        "    <tr>", 
        "      <th>turn</th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "    </tr>", 
        "  </thead>", 
        "  <tbody>", 
        "    <tr>", 
        "      <th>1</th>", 
        "      <td>  150</td>", 
        "      <td>  54</td>", 
        "      <td> 27</td>", 
        "      <td>  22</td>", 
        "      <td>  416</td>", 
        "      <td> Moderator</td>", 
        "      <td> 20</td>", 
        "      <td> Good evening from the Magness Arena at the Uni...</td>", 
        "      <td> [good, evening, from, the, magness, arena, at,...</td>", 
        "      <td> 257</td>", 
        "      <td> 2.567901e-09</td>", 
        "      <td> 5.000000e-10</td>", 
        "      <td>  5.555556</td>", 
        "      <td> 2.454545</td>", 
        "      <td> {'right': True, 'people': True, 'romney': True...</td>", 
        "      <td> 23</td>", 
        "    </tr>", 
        "    <tr>", 
        "      <th>2</th>", 
        "      <td> 1928</td>", 
        "      <td> 235</td>", 
        "      <td> 49</td>", 
        "      <td> 293</td>", 
        "      <td> 3976</td>", 
        "      <td>     Obama</td>", 
        "      <td> 22</td>", 
        "      <td> Well, thank you very much, Jim, for this oppor...</td>", 
        "      <td> [well, thank, you, very, much, jim, for, this,...</td>", 
        "      <td> 278</td>", 
        "      <td> 3.750943e-08</td>", 
        "      <td> 9.311321e-09</td>", 
        "      <td> 39.346939</td>", 
        "      <td> 0.802048</td>", 
        "      <td> {'reduce': True, 'says': True, 'people': True,...</td>", 
        "      <td> 47</td>", 
        "    </tr>", 
        "  </tbody>", 
        "</table>", 
        "</div>"
       ], 
       "output_type": "pyout", 
       "prompt_number": 167, 
       "text": [
        "      agree_dem  agree_rep  disagree_dem  disagree_rep  reactions    speaker  \\", 
        "turn                                                                           ", 
        "1           150         54            27            22        416  Moderator   ", 
        "2          1928        235            49           293       3976      Obama   ", 
        "", 
        "      statements                                               text  \\", 
        "turn                                                                  ", 
        "1             20  Good evening from the Magness Arena at the Uni...   ", 
        "2             22  Well, thank you very much, Jim, for this oppor...   ", 
        "", 
        "                                                  words  word_count     r_per_sec  \\", 
        "turn                                                                                ", 
        "1     [good, evening, from, the, magness, arena, at,...         257  2.567901e-09   ", 
        "2     [well, thank, you, very, much, jim, for, this,...         278  3.750943e-08   ", 
        "", 
        "        sd_per_sec  a_to_d_dems  a_to_d_reps  \\", 
        "turn                                           ", 
        "1     5.000000e-10     5.555556     2.454545   ", 
        "2     9.311321e-09    39.346939     0.802048   ", 
        "", 
        "                                               unigrams  unigram_count  ", 
        "turn                                                                    ", 
        "1     {'right': True, 'people': True, 'romney': True...             23  ", 
        "2     {'reduce': True, 'says': True, 'people': True,...             47  "
       ]
      }
     ], 
     "prompt_number": 167
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "### Filter"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "For now, we get rid of the really short turns."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "#MIN_WORDS = 30 # good results", 
      "MIN_WORDS = 0 # this really affects the republican results strongly", 
      "t2 = t[t.word_count >= MIN_WORDS]", 
      "print len(t),'->',len(t2)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "181 -> 181"
       ]
      }
     ], 
     "prompt_number": 284
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Crossvalidation code"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "def cv(df, num_folds = 10, classifier=nltk.NaiveBayesClassifier, maxent_params=None):", 
      "    df = df.copy()", 
      "    df = df.reindex(np.random.permutation(e2b.index))", 
      "    fold_size = len(df)/num_folds", 
      "    fold_starts = range(0, len(df)+fold_size, fold_size)", 
      "    folds = zip(fs,fs[1:])", 
      "    accs = []", 
      "    for (first,last) in folds:", 
      "        test_rows = df.index[first:last]", 
      "        tst = df.ix[test_rows]", 
      "        trn = df.drop(test_rows)", 
      "        if maxent_params == None:", 
      "            cl = classifier.train(zip(trn.unigrams, trn.label))", 
      "        else:", 
      "            cl = classifier.train(zip(trn.unigrams, trn.label), ", 
      "                                  algorithm=maxent_params['algorithm'], ", 
      "                                  max_iter=maxent_params['max_iter'],", 
      "                                  trace=maxent_params['trace'])", 
      "        accs.append(nltk.classify.accuracy(cl, zip(tst.unigrams, tst.label)))", 
      "    return {'mean':mean(accs),'stdev':std(accs)}"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 303
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Task 1: Reactions per second"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e1 = t2.copy()", 
      "e1['label'] = e1.r_per_sec >= e1.r_per_sec.quantile(.5)", 
      "print 'NB', cv(e1, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e1, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e1, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.071428571428571397, 'mean': 0.7857142857142857}"
       ]
      }
     ], 
     "prompt_number": 306
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Task 2a: Majority agrees with speaker"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Democrats"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e2ad = t2.copy()", 
      "e2ad['label'] = e2ad.agree_dem >= e2ad.disagree_dem", 
      "print 'NB', cv(e2ad, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e2ad, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e2ad, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.20404081224408144, 'mean': 0.80000000000000004}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.14356965173029843, 'mean': 0.81428571428571428}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.13093073414159542, 'mean': 0.80000000000000004}"
       ]
      }
     ], 
     "prompt_number": 307
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Republicans"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e2ar = t2.copy()", 
      "e2ar['label'] = e2ar.agree_rep >= e2ar.disagree_rep", 
      "print 'NB', cv(e2ar, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e2ar, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e2ar, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.25714285714285717, 'mean': 0.62857142857142856}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.11517511068997928, 'mean': 0.78571428571428559}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.15714285714285717, 'mean': 0.75714285714285712}"
       ]
      }
     ], 
     "prompt_number": 308
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Task 2b: Ratio agree-to-disagree above median"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Democrats"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e2bd = t2.copy()", 
      "e2bd['label'] = e2bd.a_to_d_dems >= e2bd.a_to_d_dems.quantile(.5)", 
      "print 'NB', cv(e2bd, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e2bd, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e2bd, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.14356965173029843, 'mean': 0.75714285714285701}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.094760708295868551, 'mean': 0.80000000000000004}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.10690449676496976, 'mean': 0.82857142857142851}"
       ]
      }
     ], 
     "prompt_number": 309
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Republicans"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e2br = t2.copy()", 
      "e2br['label'] = e2br.a_to_d_reps >= e2br.a_to_d_reps.quantile(.5)", 
      "print 'NB', cv(e2br, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e2br, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e2br, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.25911938781738653, 'mean': 0.44285714285714278}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.076930925816207196, 'mean': 0.84285714285714275}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.11866605518454393, 'mean': 0.84285714285714275}"
       ]
      }
     ], 
     "prompt_number": 310
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Task 3: Spins+dodges per second above median"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e3 = t2.copy()", 
      "e3['label'] = e3.sd_per_sec >= e3.sd_per_sec.quantile(.5)", 
      "print 'NB', cv(e3, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e3, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e3, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.18070158058105026, 'mean': 0.71428571428571419}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.20000000000000001, 'mean': 0.68571428571428572}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.11866605518454391, 'mean': 0.72857142857142843}"
       ]
      }
     ], 
     "prompt_number": 311
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": []
    }
   ]
  }
 ]
}