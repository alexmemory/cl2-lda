{
 "metadata": {
  "name": "notes_turns_and_reactions3"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown", 
     "source": [
      "# Reactions per turn"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Focusing on generating evaluation results for our specific tasks."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "import pandas as pd", 
      "import reactions", 
      "import nltk", 
      "import random", 
      "import matplotlib.pyplot as plt", 
      "from pandas.tools.plotting import scatter_matrix", 
      "from nltk.corpus import stopwords"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "%time r = reactions.link_reactions_to_transcript('data/reactions_oct3_4project.csv','corpora/oct3_coded_transcript_sync.csv')"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "CPU times: user 8.41 s, sys: 0.52 s, total: 8.93 s", 
        "Wall time: 8.93 s"
       ]
      }
     ], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "r2 = r.copy()", 
      "#del r2[\"Sync'd start\"]", 
      "#del r2[\"Sync'd end\"]", 
      "del r2[\"Time\"]", 
      "del r2[\"Speaker\"]", 
      "#r2.head(2)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 3
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Political questionnaire data"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "%time p = reactions.split_reactions_file('data/reactions_oct3_4project.csv')['quest_political']"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "CPU times: user 4.79 s, sys: 0.37 s, total: 5.16 s", 
        "Wall time: 5.16 s"
       ]
      }
     ], 
     "prompt_number": 331
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "p2 = p[['UserID','party_1','political_views_2','candidate_choice_3','confidence_in_choice_4','likely_to_vote_5','candidate_preferred_29']]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 11
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Simplify party membership into R/D/oth"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "p2['party'] = p2.party_1.apply(lambda a: {'closest to democratic party':'democrat', ", 
      "                                          'lean democrat':'democrat',", 
      "                                          'lean republican':'republican',", 
      "                                          'closest to republican party':'republican'}.get(a,'other'))", 
      "p2['candidate'] = p2.candidate_choice_3", 
      "#p2['candidate'] = p2.candidate_choice_3.apply(lambda a: {'obama':'democrat', ", 
      "#                                          'lean democrat':'democrat',", 
      "#                                          'lean republican':'republican',", 
      "#                                          'closest to republican party':'republican'}.get(a,'other'))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 333
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "### Merge political questionnaire with reactions"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "%time r3 = r2.merge(p2[['UserID','party','candidate']])", 
      "print 'pre-merge:',len(r2),'post-merge:',len(r3)", 
      "#r3.head(2)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "CPU times: user 0.62 s, sys: 0.05 s, total: 0.66 s", 
        "Wall time: 0.66 s", 
        "pre-merge: 189015 post-merge: 189015"
       ]
      }
     ], 
     "prompt_number": 334
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Limit to reactions to the speaker of the ***current turn***."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "r4 = r3[r3.Reaction_who == r3.Speaker_name]", 
      "print 'before:',len(r3),'current-speaker-only:',len(r4), 'difference:',len(r4)-len(r3), 1.0*(len(r4)-len(r3))/len(r4),'percent'"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "before: 189015 current-speaker-only: 156622 difference: -32393 -0.206822796287 percent"
       ]
      }
     ], 
     "prompt_number": 335
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Group by turn"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Statements"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "st = r4.groupby(['statement']).first()[['Speaker_name','Transcript','turn',\"Sync'd start\",\"Sync'd end\"]]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 17
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Turns"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "t = pd.DataFrame({'speaker':st.groupby('turn').first().Speaker_name, ", 
      "                  'start':st.groupby('turn').first()[\"Sync'd start\"],", 
      "                  'end':st.groupby('turn').last()[\"Sync'd end\"],", 
      "                  #'reactions':r4.groupby('turn').count().Speaker_name, ", 
      "                  'reactions_oba':r4[(r4.candidate=='obama')].groupby('turn').count().turn,", 
      "                  'reactions_rom':r4[(r4.candidate=='romney')].groupby('turn').count().turn,", 
      "                  'spin_rom':r4[(r4.candidate=='romney') & (r4.Reaction_what=='Spin')].groupby('turn').count().turn,", 
      "                  'statements':st.groupby('turn').count().turn, ", 
      "                  'text':st.groupby('turn').apply(lambda x: ''.join(x.Transcript)),", 
      "                  'agree':r4[r4.Reaction_what=='Agree'].groupby('turn').count().turn,", 
      "                  #'agree_dem':r4[(r4.party=='democrat') & (r4.Reaction_what=='Agree')].groupby('turn').count().turn,", 
      "                  #'agree_rep':r4[(r4.party=='republican') & (r4.Reaction_what=='Agree')].groupby('turn').count().turn,", 
      "                  'agree_oba':r4[(r4.candidate=='obama') & (r4.Reaction_what=='Agree')].groupby('turn').count().turn,", 
      "                  'agree_rom':r4[(r4.candidate=='romney') & (r4.Reaction_what=='Agree')].groupby('turn').count().turn,", 
      "                  'disagree':r4[r4.Reaction_what=='Disagree'].groupby('turn').count().turn,", 
      "                  #'disagree_dem':r4[(r4.party=='democrat') & (r4.Reaction_what=='Disagree')].groupby('turn').count().turn,", 
      "                  #'disagree_rep':r4[(r4.party=='republican') & (r4.Reaction_what=='Disagree')].groupby('turn').count().turn,", 
      "                  'disagree_oba':r4[(r4.candidate=='obama') & (r4.Reaction_what=='Disagree')].groupby('turn').count().turn,", 
      "                  'disagree_rom':r4[(r4.candidate=='romney') & (r4.Reaction_what=='Disagree')].groupby('turn').count().turn,", 
      "                  'dodge_oba':r4[(r4.candidate=='obama') & (r4.Reaction_what=='Dodge')].groupby('turn').count().turn,", 
      "                  'dodge_rom':r4[(r4.candidate=='romney') & (r4.Reaction_what=='Dodge')].groupby('turn').count().turn,", 
      "                  'dodge':r4[r4.Reaction_what=='Dodge'].groupby('turn').count().turn,", 
      "                  'spin_oba':r4[(r4.candidate=='obama') & (r4.Reaction_what=='Spin')].groupby('turn').count().turn,", 
      "                  'spin_rom':r4[(r4.candidate=='romney') & (r4.Reaction_what=='Spin')].groupby('turn').count().turn,", 
      "                  'spin':r4[r4.Reaction_what=='Spin'].groupby('turn').count().turn,", 
      "                  })", 
      "tmpstart = pd.to_datetime(t.start)", 
      "tmpend = pd.to_datetime(t.end)", 
      "t['dur'] = (tmpend - tmpstart)", 
      "t.duration = 1.0 * t.dur / 1000000000.0", 
      "t['words'] = t.text.apply(lambda txt: [tok.lower() for tok in nltk.tokenize.word_tokenize(txt) if tok.isalpha()])", 
      "t['word_count'] = t.words.apply(lambda words: len(words))", 
      "#t['r_per_st'] = 1.0 * t.reactions / t.statements", 
      "#t['r_per_w'] = 1.0 * t.reactions / t.word_count", 
      "#t['r_per_sec'] = 1.0 * t.reactions / t.dur", 
      "t['rps_oba'] = 1.0 * t.reactions_oba / t.dur", 
      "t['rps_rom'] = 1.0 * t.reactions_rom / t.dur", 
      "#t['sd_per_sec'] = 1.0 * (t.spin + t.dodge) / t.dur", 
      "t['sdps_oba'] = 1.0 * (t.spin_oba + t.dodge_oba) / t.dur", 
      "t['sdps_rom'] = 1.0 * (t.spin_rom + t.dodge_rom) / t.dur", 
      "#t['a_to_d_dems'] = t.agree_dem / t.disagree_dem", 
      "#t['a_to_d_reps'] = t.agree_rep / t.disagree_rep", 
      "t['a_to_d_oba'] = t.agree_oba / t.disagree_oba", 
      "t['a_to_d_rom'] = t.agree_rom / t.disagree_rom", 
      "", 
      "del t['agree']", 
      "#del t['agree_dem']", 
      "#del t['agree_rep']", 
      "del t['disagree']", 
      "#del t['disagree_dem']", 
      "#del t['disagree_rep']", 
      "del t['dodge']", 
      "del t['spin']", 
      "del t['r_per_st']", 
      "del t['r_per_w']", 
      "del t['start']", 
      "del t['end']", 
      "del t['dur']"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 341
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "ranked_unigrams = nltk.FreqDist([w for word_list in t.words for w in word_list]).keys()", 
      "MAX_FEATURES = 200 # avoid overfitting", 
      "t['unigrams'] = t.words.apply(lambda words: {w:True for w in words if w in ranked_unigrams[:MAX_FEATURES] and not w in stopwords.words('english')})", 
      "t['bigrams'] = t.words.apply(lambda words: {\"%s_%s\"%(w1,w2):True for w1,w2 in nltk.bigrams(words) if ", 
      "                                            (w1 in ranked_unigrams[:MAX_FEATURES]) and", 
      "                                            (w2 in ranked_unigrams[:MAX_FEATURES]) and", 
      "                                            (not w1 in stopwords.words('english')) and", 
      "                                            (not w2 in stopwords.words('english'))", 
      "                                            })"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 342
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "t.head(2)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">", 
        "<table border=\"1\" class=\"dataframe\">", 
        "  <thead>", 
        "    <tr style=\"text-align: right;\">", 
        "      <th></th>", 
        "      <th>agree_oba</th>", 
        "      <th>agree_rom</th>", 
        "      <th>disagree_oba</th>", 
        "      <th>disagree_rom</th>", 
        "      <th>reactions</th>", 
        "      <th>speaker</th>", 
        "      <th>statements</th>", 
        "      <th>text</th>", 
        "      <th>words</th>", 
        "      <th>word_count</th>", 
        "      <th>r_per_sec</th>", 
        "      <th>sd_per_sec</th>", 
        "      <th>a_to_d_oba</th>", 
        "      <th>a_to_d_rom</th>", 
        "      <th>unigrams</th>", 
        "      <th>bigrams</th>", 
        "    </tr>", 
        "    <tr>", 
        "      <th>turn</th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "      <th></th>", 
        "    </tr>", 
        "  </thead>", 
        "  <tbody>", 
        "    <tr>", 
        "      <th>1</th>", 
        "      <td>  175</td>", 
        "      <td>  51</td>", 
        "      <td> 30</td>", 
        "      <td>  16</td>", 
        "      <td>  416</td>", 
        "      <td> Moderator</td>", 
        "      <td> 20</td>", 
        "      <td> Good evening from the Magness Arena at the Uni...</td>", 
        "      <td> [good, evening, from, the, magness, arena, at,...</td>", 
        "      <td> 257</td>", 
        "      <td> 2.567901e-09</td>", 
        "      <td> 5.000000e-10</td>", 
        "      <td>  5.833333</td>", 
        "      <td> 3.187500</td>", 
        "      <td> {'right': True, 'people': True, 'romney': True...</td>", 
        "      <td> {'two_minutes': True, 'would_go': True, 'new_j...</td>", 
        "    </tr>", 
        "    <tr>", 
        "      <th>2</th>", 
        "      <td> 2103</td>", 
        "      <td> 170</td>", 
        "      <td> 50</td>", 
        "      <td> 286</td>", 
        "      <td> 3976</td>", 
        "      <td>     Obama</td>", 
        "      <td> 22</td>", 
        "      <td> Well, thank you very much, Jim, for this oppor...</td>", 
        "      <td> [well, thank, you, very, much, jim, for, this,...</td>", 
        "      <td> 278</td>", 
        "      <td> 3.750943e-08</td>", 
        "      <td> 9.311321e-09</td>", 
        "      <td> 42.060000</td>", 
        "      <td> 0.594406</td>", 
        "      <td> {'reduce': True, 'says': True, 'people': True,...</td>", 
        "      <td> {'four_years': True, 'better_got': True, 'smal...</td>", 
        "    </tr>", 
        "  </tbody>", 
        "</table>", 
        "</div>"
       ], 
       "output_type": "pyout", 
       "prompt_number": 343, 
       "text": [
        "      agree_oba  agree_rom  disagree_oba  disagree_rom  reactions    speaker  \\", 
        "turn                                                                           ", 
        "1           175         51            30            16        416  Moderator   ", 
        "2          2103        170            50           286       3976      Obama   ", 
        "", 
        "      statements                                               text  \\", 
        "turn                                                                  ", 
        "1             20  Good evening from the Magness Arena at the Uni...   ", 
        "2             22  Well, thank you very much, Jim, for this oppor...   ", 
        "", 
        "                                                  words  word_count     r_per_sec  \\", 
        "turn                                                                                ", 
        "1     [good, evening, from, the, magness, arena, at,...         257  2.567901e-09   ", 
        "2     [well, thank, you, very, much, jim, for, this,...         278  3.750943e-08   ", 
        "", 
        "        sd_per_sec  a_to_d_oba  a_to_d_rom  \\", 
        "turn                                         ", 
        "1     5.000000e-10    5.833333    3.187500   ", 
        "2     9.311321e-09   42.060000    0.594406   ", 
        "", 
        "                                               unigrams  \\", 
        "turn                                                      ", 
        "1     {'right': True, 'people': True, 'romney': True...   ", 
        "2     {'reduce': True, 'says': True, 'people': True,...   ", 
        "", 
        "                                                bigrams  ", 
        "turn                                                     ", 
        "1     {'two_minutes': True, 'would_go': True, 'new_j...  ", 
        "2     {'four_years': True, 'better_got': True, 'smal...  "
       ]
      }
     ], 
     "prompt_number": 343
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "### Filter"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "For now, we get rid of the really short turns."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "#MIN_WORDS = 30 # good results", 
      "MIN_WORDS = 0 # this really affects the republican results strongly", 
      "t2 = t[t.word_count >= MIN_WORDS]", 
      "print len(t),'->',len(t2)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "181 -> 181"
       ]
      }
     ], 
     "prompt_number": 344
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Crossvalidation code"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "def cv(df, num_folds = 10, classifier=nltk.NaiveBayesClassifier, maxent_params=None):", 
      "    df = df.copy()", 
      "    df = df.reindex(np.random.permutation(e2b.index))", 
      "    fold_size = len(df)/num_folds", 
      "    fold_starts = range(0, len(df)+fold_size, fold_size)", 
      "    folds = zip(fs,fs[1:])", 
      "    accs = []", 
      "    for (first,last) in folds:", 
      "        test_rows = df.index[first:last]", 
      "        tst = df.ix[test_rows]", 
      "        trn = df.drop(test_rows)", 
      "        if maxent_params == None:", 
      "            cl = classifier.train(zip(trn.features, trn.label))", 
      "        else:", 
      "            cl = classifier.train(zip(trn.features, trn.label), ", 
      "                                  algorithm=maxent_params['algorithm'], ", 
      "                                  max_iter=maxent_params['max_iter'],", 
      "                                  trace=maxent_params['trace'])", 
      "        accs.append(nltk.classify.accuracy(cl, zip(tst.unigrams, tst.label)))", 
      "    return {'mean':mean(accs),'stdev':std(accs)}"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 345
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Task 1: Reactions per second"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "#a = {'a1':1,'a2':2}", 
      "#b = {'b1':1,'b2':2}", 
      "#dict(a.items() + b.items())"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 346
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "t2['features'] = t2.unigrams", 
      "#t.map(lambda row: dict(row['unigrams'].items() + row['bigrams'].items()))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 350
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e1 = t2.copy()", 
      "e1['label'] = e1.r_per_sec >= e1.r_per_sec.quantile(.5)", 
      "print 'NB', cv(e1, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e1, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e1, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.13997084244475305, 'mean': 0.74285714285714266}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.14568627181693672, 'mean': 0.79999999999999993}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.11517511068997928, 'mean': 0.7857142857142857}"
       ]
      }
     ], 
     "prompt_number": 351
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Task 2a: Majority agrees with speaker"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Democrats"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e2ad = t2.copy()", 
      "#e2ad['label'] = e2ad.agree_dem >= e2ad.disagree_dem", 
      "e2ad['label'] = e2ad.agree_oba >= e2ad.disagree_oba", 
      "print 'NB', cv(e2ad, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e2ad, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e2ad, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.15649215928719032, 'mean': 0.8571428571428571}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.10690449676496974, 'mean': 0.74285714285714277}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.15386185163241442, 'mean': 0.82857142857142851}"
       ]
      }
     ], 
     "prompt_number": 352
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Republicans"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e2ar = t2.copy()", 
      "#e2ar['label'] = e2ar.agree_rep >= e2ar.disagree_rep", 
      "e2ar['label'] = e2ar.agree_rom >= e2ar.disagree_rom", 
      "print 'NB', cv(e2ar, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e2ar, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e2ar, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.22314999074019012, 'mean': 0.48571428571428565}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.16963345838625599, 'mean': 0.81428571428571428}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.14638501094227999, 'mean': 0.78571428571428559}"
       ]
      }
     ], 
     "prompt_number": 354
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Task 2b: Ratio agree-to-disagree above median"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Democrats"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e2bd = t2.copy()", 
      "#e2bd['label'] = e2bd.a_to_d_dems >= e2bd.a_to_d_dems.quantile(.5)", 
      "e2bd['label'] = e2bd.a_to_d_oba >= e2bd.a_to_d_oba.quantile(.5)", 
      "print 'NB', cv(e2bd, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e2bd, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e2bd, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.17142857142857146, 'mean': 0.77142857142857146}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.11428571428571428, 'mean': 0.77142857142857146}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.12777531299998798, 'mean': 0.8571428571428571}"
       ]
      }
     ], 
     "prompt_number": 353
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Republicans"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e2br = t2.copy()", 
      "#e2br['label'] = e2br.a_to_d_reps >= e2br.a_to_d_reps.quantile(.5)", 
      "e2br['label'] = e2br.a_to_d_rom >= e2br.a_to_d_rom.quantile(.5)", 
      "print 'NB', cv(e2br, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e2br, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e2br, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.15714285714285714, 'mean': 0.61428571428571421}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.10690449676496974, 'mean': 0.74285714285714277}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.15714285714285714, 'mean': 0.75714285714285712}"
       ]
      }
     ], 
     "prompt_number": 355
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Task 3: Spins+dodges per second above median"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "e3 = t2.copy()", 
      "e3['label'] = e3.sd_per_sec >= e3.sd_per_sec.quantile(.5)", 
      "print 'NB', cv(e3, classifier=nltk.NaiveBayesClassifier)", 
      "print 'DT', cv(e3, classifier=nltk.classify.DecisionTreeClassifier)", 
      "print 'ME', cv(e3, classifier=nltk.classify.MaxentClassifier, ", 
      "               maxent_params={'algorithm':nltk.classify.MaxentClassifier.ALGORITHMS[0], ", 
      "                              'max_iter':25,", 
      "                              'trace':0})"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "NB "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.18070158058105026, 'mean': 0.71428571428571419}", 
        "DT "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.20000000000000001, 'mean': 0.68571428571428572}", 
        "ME "
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "{'stdev': 0.11866605518454391, 'mean': 0.72857142857142843}"
       ]
      }
     ], 
     "prompt_number": 311
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": []
    }
   ]
  }
 ]
}