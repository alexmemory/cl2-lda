%!TEX root =  cl2-lda.tex

\subsubsection{Data}

We used the annotated October 3rd 2013 presidential debate and the annonated presidential debate corpus (both obtained through Philip Resnik).
Together, the corpora are approximately 12,000 lines long.
Each line is comprised of a statement and metadata about that statement (speaker, tone, topic, etc...).
We had to preprocess the corpora, first by tokenizing it into turns in each debate, and second by performing normal preprocessing steps (e.g., tokenizing into words and removing stopwords).

In addition to the corpora, we also used the reaction data from ReactLabs (also provided by Philip Resnik).
This dataset contained 193,287 reactions to the October 3rd presidential debate.
Each line in the file corresponded to a single reaction (Romney:Disagree, Obama:Spin, etc...) with a timestamp and metadata about the user who submitted the reaction.

\subsubsection{Resources}

We used the Machine Learning for Language Toolkit (Mallet) for several tasksin the project.
First, we used it to infer topics from the debate corpus.
Second, we used it to train several different classifiers (Decision Tree, MaxEnt, Naive Bayes).

We also used several Python modules for various jobs.
We used the natural language toolkit (nltk) for preprocessing tasks (e.g., sentence and word tokenization, removing stopwords, etc...).
We used numpy, scipy, matplotlib, and pandas for data analysis.
Finally, we used sqlite3 to store the reactions data in a format that is easier to filter.
