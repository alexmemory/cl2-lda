%!TEX root =  cl2-lda.tex

Predicting users' reactions to the debate based on n-grams from the text of the each turn taken by the candidates is a simple approach, and we are interested to see how well the topic-based methods compare to it in terms of performance.

On all the tasks, we predict the responses to turns using Decision Tree, Maximum Entropy and Naive Bayes classifiers; we used the implementations of these classifiers from NLTK~\cite{bird_nltk:_2006}.  We measure our final accuracy on all tasks with 10-fold cross validation.  

To extract n-gram features from the transcripts of the turns, we began by splitting the text into tokens using the English tokenizer from NLTK.  We then removed punctuation, numbers and stop-words; and then converted all n-grams to lower-case.  Finally, we produced a single feature for each unique n-gram in each turn indicating is presence (not the count of tokens for that n-gram).  

For our evaluation, we considered either unigrams or bigrams as features.  To determine the number of n-gram features to use to avoid overfitting, we varied their number while evaluating mean accuracy during repeated random sub-sampling validation.  To select which n-grams to include among the features, we selected the most frequent n-grams first.

First we consider results with unigram features. In Table~\ref{tab:task1unigrams} we see that on \textbf{Task 1} the Decision Tree performed best over all, while on \textbf{Task 2}, Naive Bayes performed very well when predicting reactions of Obama voters but not for Romney voters, cf. Table~\ref{tab:task2unigrams}.  And, we see in~\ref{tab:task3unigrams} that on \textbf{Task 3}, Maximum Entropy performed best over all while Naive Bayes continued to struggle at predicting reactions of Romney voters.

\begin{table}[H]
\begin{centering}
\begin{tabular}{ l | l | l }
Classifier & Obama voters & Romney voters \\
\hline
DecTree & \textbf{0.84} (0.07) &  \textbf{0.83} (0.17) \\
MaxEnt & \textbf{0.78} (.16) &  \textbf{.84} (.16) \\
Naive & \textbf{0.75} (.09) &  \textbf{.77} (.15) \\
\end{tabular}
\caption{Task 1 (unigram features): Accuracy and StdDev}
\label{tab:task1unigrams}
\end{centering}
\end{table}

\begin{table}[H]
\begin{centering}
\begin{tabular}{ l | l | l }
Classifier & Obama voters & Romney voters \\
\hline
DecTree & \textbf{0.74} (0.22) &  \textbf{0.83} (0.12) \\
MaxEnt & \textbf{0.76} (.16) &  \textbf{.80} (.06) \\
Naive & \textbf{0.87} (.12) &  \textbf{.50} (.12) \\
\end{tabular}
\caption{Task 2 (unigram features): Accuracy and StdDev}
\label{tab:task2unigrams}
\end{centering}
\end{table}

\begin{table}[H]
\begin{centering}
\begin{tabular}{ l | l | l }
Classifier & Obama voters & Romney voters \\
\hline
DecTree & \textbf{0.83} (0.14) &  \textbf{0.80} (0.15) \\
MaxEnt & \textbf{0.86} (.09) &  \textbf{.84} (.13) \\
Naive & \textbf{0.81} (.11) &  \textbf{.49} (.23) \\
\end{tabular}
\caption{Task 3 (unigram features): Accuracy and StdDev}
\label{tab:task3unigrams}
\end{centering}
\end{table}

Bigram features consistently underperform the unigram features, since there were very few training examples, permitting over-fitting, and the models were not smoothed.  Table~\ref{tab:task1bigrams} reveals marginal performance on \textbf{Task 1}, but \textbf{Task 2} and \textbf{Task 3} performed worse, cf. Table~\ref{tab:task2bigrams} and Table~\ref{tab:task3bigrams}.

\begin{table}[H]
\begin{centering}
\begin{tabular}{ l | l | l }
Classifier & Obama voters & Romney voters \\
\hline
DecTree & \textbf{0.74} (0.12) &  \textbf{0.73} (0.12) \\
MaxEnt & \textbf{0.74} (.09) &  \textbf{.73} (.10) \\
Naive & \textbf{0.74} (.09) &  \textbf{.73} (.17) \\
\end{tabular}
\caption{Task 1 (bigram features): Accuracy and StdDev}
\label{tab:task1bigrams}
\end{centering}
\end{table}

\begin{table}[H]
\begin{centering}
\begin{tabular}{ l | l | l }
Classifier & Obama voters & Romney voters \\
\hline
DecTree & \textbf{0.46} (0.18) &  \textbf{0.63} (0.13) \\
MaxEnt & \textbf{0.54} (.11) &  \textbf{.63} (.17) \\
Naive & \textbf{0.44} (.22) &  \textbf{.63} (.21) \\
\end{tabular}
\caption{Task 2 (bigram features): Accuracy and StdDev}
\label{tab:task2bigrams}
\end{centering}
\end{table}

\begin{table}[H]
\begin{centering}
\begin{tabular}{ l | l | l }
Classifier & Obama voters & Romney voters \\
\hline
DecTree & \textbf{0.50} (0.09) &  \textbf{0.60} (0.19) \\
MaxEnt & \textbf{0.50} (.24) &  \textbf{.40} (.22) \\
Naive & \textbf{0.33} (.13) &  \textbf{.60} (.11) \\
\end{tabular}
\caption{Task 3 (bigram features): Accuracy and StdDev}
\label{tab:task3bigrams}
\end{centering}
\end{table}