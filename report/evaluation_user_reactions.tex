
In the previous sections, we predict reactions to a turn based on the topics present in the turn. We find that we can do this reasonably well for some types of prediction, and also learn what topics contribute most certain reactions.

We can also ask what topics cause an individual user to react, rather than users in general. The label for prediction then becomes that user's reaction, and the features become the topics present in the discussion at the time of the reaction.

However, since we are now working at the individual level, we can also use features based on a user's responses to the ReactLabs survey questions, which we will call "user features." These include questions such as gender and political party, and also questions that ask the user to indicate agreement with one party or another on specific issues with a value between 0 and 100.

We are primarily interested in 1.) how well we can predict user reactions given user features and topic features, and 2.) how much topic features contribute to classification accuracy. Topic features are determined based on the turn in which the reaction occurs. We use features derived from both LDA topics and the Boydstun labeled topics. Labels are the 12 possible user reactions ("$Obama|Romney|Moderator : Agree|Disagree|Spin|Dodge$"). We use 10,000 reactions for 10-fold cross-validation.

\begin{table*}[H]
\begin{centering}
\begin{tabular}{ l | l | l | l }
Classifier & User features only & User + LDA & User + Boydstun \\
\hline
Decision Tree & \textbf{0.389} (.018) & \textbf{0.397} (.016) &  \textbf{.388} (.014) \\
Maximum Entropy & \textbf{.452} (.019) & \textbf{0.517} (.012) &  \textbf{.508} (.022) \\
Naive Bayes & \textbf{.443} (.020) & \textbf{0.481} (.012) &  \textbf{.460} (.013) \\
\end{tabular}
\caption{User reaction classification: accuracy and standard deviation}
\end{centering}
\end{table*}

We also plot confusion matrices using the best-performing classifier for both user features alone and user features combined with topic features.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{Figures/no_topic_features_confusion.png}
	\caption{Confusion Matrix: Classification with user features only}
	\label{fig:useronlyconfusion}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{Figures/boydstun_confusion.png}
	\caption{Confusion Matrix: Classification with user and topic features}
	\label{fig:boydstunconfusion}
\end{figure}


\begin{table}[H]
\begin{centering}
\begin{tabular}{ l | l | l | l }
 Code & Topic & Code & Topic \\
\hline
4 & Moderator:Agree & 9 & Romney:Dodge \\
6 & Obama:Spin & 3 & Romney:Disagree \\
7 & Obama:Dodge & 1 & Obama:Disagree \\
0 & Obama:Agree & 10 & Moderator:Spin \\
8 & Romney:Spin & 11 & Moderator:Dodge \\
2 & Romney:Agree & 5 & Moderator:Disagree \\

\end{tabular}
\caption{Topic code key}
\end{centering}
\end{table}